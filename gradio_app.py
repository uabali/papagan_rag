import gradio as gr
import os
import glob
import torch
import whisper
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters.character import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_community.llms import Ollama
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv

load_dotenv()

# KlasÃ¶rleri oluÅŸtur
pdf_folder = "data"
audio_folder = "ses_data"
os.makedirs(pdf_folder, exist_ok=True)
os.makedirs(audio_folder, exist_ok=True)

print("ğŸš€ Sistem baÅŸlatÄ±lÄ±yor...")

# Whisper modelini yÃ¼kle
print("ğŸ“¥ Whisper modeli yÃ¼kleniyor...")
device = "cuda" if torch.cuda.is_available() else "cpu"
whisper_model = whisper.load_model("medium", device=device)
print(f"âœ… Whisper yÃ¼klendi ({device})")

# Embeddings modelini yÃ¼kle
print("ğŸ“¥ Embedding modeli yÃ¼kleniyor...")
embeddings = HuggingFaceEmbeddings(
    model_name="BAAI/bge-m3",
    model_kwargs={"device": "cpu"},
    encode_kwargs={"normalize_embeddings": True}
)
print("âœ… Embedding modeli yÃ¼klendi")

# Vector store'u yÃ¼kle veya oluÅŸtur
def initialize_vectorstore():
    """Vector store'u baÅŸlat"""
    pdf_files = glob.glob(os.path.join(pdf_folder, "*.pdf"))
    
    if not pdf_files:
        print("âš ï¸ HenÃ¼z PDF dosyasÄ± yÃ¼klenmemiÅŸ!")
        return None
    
    print(f"ğŸ“š {len(pdf_files)} PDF dosyasÄ± bulundu")
    
    if os.path.exists("./chroma_db"):
        print("ğŸ“‚ Mevcut veritabanÄ± yÃ¼kleniyor...")
        vectorstore = Chroma(
            persist_directory="./chroma_db",
            embedding_function=embeddings
        )
    else:
        print("ğŸ”¨ Yeni veritabanÄ± oluÅŸturuluyor...")
        documents = []
        for pdf_path in pdf_files[:5]:  # Ä°lk 5 PDF
            loader = PyPDFLoader(pdf_path)
            documents.extend(loader.load())
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=800,
            chunk_overlap=120
        )
        docs = text_splitter.split_documents(documents)
        
        vectorstore = Chroma.from_documents(
            documents=docs,
            embedding=embeddings,
            persist_directory="./chroma_db"
        )
    
    print("âœ… VeritabanÄ± hazÄ±r")
    return vectorstore

vectorstore = initialize_vectorstore()

# LLM'i baÅŸlat
print("ğŸ¤– Ollama LLM baÅŸlatÄ±lÄ±yor...")
"""llm = Ollama(
    model="llama3:8b",
    temperature=0.1
)
"""


llm = ChatOpenAI(
    base_url="http://localhost:1234/v1",
    api_key="lm-studio",
    model_name="qwen3-vl-2b-instruct",
    temperature=0.1
)




print("âœ… LLM hazÄ±r")

# RAG chain'i oluÅŸtur
retriever = None

def create_rag_chain():
    """RAG chain'i oluÅŸtur"""
    global retriever
    
    if vectorstore is None:
        return None
    
    retriever = vectorstore.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 6}
    )
    
    def format_docs(docs):
        return "\n\n".join(doc.page_content for doc in docs)
    
    prompt = PromptTemplate(
        input_variables=["context", "question"],
        template="""
You are a retrieval-based assistant.
Answer the user's question using ONLY the given CONTEXT.
Do NOT use external knowledge.
Do NOT make assumptions or hallucinate.

Rules:
- Write the answer in TURKISH using ONLY ASCII characters.
- Do NOT use Turkish characters like: Ã§, ÄŸ, ÅŸ, Ä±, Ä°, Ã¶, Ã¼.
- The answer should be CLEAR, EXPLANATORY, and 3 to 6 sentences long.
- You may rephrase the context but do NOT add new information.
- If the answer is not found in the context, respond exactly with:
  "Baglamda cevap bulunamadi."

CONTEXT:
{context}

QUESTION:
{question}

DETAILED ASCII TURKISH ANSWER:
"""
    )
    
    rag_chain = (
        {
            "context": retriever | format_docs,
            "question": RunnablePassthrough()
        }
        | prompt
        | llm
        | StrOutputParser()
    )
    
    return rag_chain

rag_chain = create_rag_chain()

print("âœ… Sistem hazÄ±r!\n")


# Gradio fonksiyonlarÄ±
def get_sources(question):
    """Soruyla ilgili kaynak dÃ¶kÃ¼manlarÄ± al"""
    if retriever is None:
        return []
    
    try:
        docs = retriever.get_relevant_documents(question)
        sources = []
        
        for i, doc in enumerate(docs):
            source_info = {
                "index": i + 1,
                "file": os.path.basename(doc.metadata.get("source", "Bilinmeyen")),
                "page": doc.metadata.get("page", "?"),
                "content": doc.page_content[:150] + "..." if len(doc.page_content) > 150 else doc.page_content
            }
            sources.append(source_info)
        
        return sources
    except:
        return []


def format_sources_html(sources):
    """KaynaklarÄ± HTML olarak formatla"""
    if not sources:
        return ""
    
    html = '<div style="margin-top: 15px; padding: 15px; background: #f8f9fa; border-radius: 10px; border-left: 4px solid #667eea;">'
    html += '<div style="font-size: 14px; font-weight: 600; color: #374151; margin-bottom: 10px;">ğŸ“š Kaynaklar:</div>'
    html += '<div style="display: flex; flex-wrap: wrap; gap: 8px; margin-bottom: 12px;">'
    
    # Kaynak chip'leri
    for source in sources:
        html += f'''
        <span style="
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 6px 14px;
            border-radius: 16px;
            font-size: 13px;
            font-weight: 500;
            display: inline-block;
            box-shadow: 0 2px 4px rgba(102, 126, 234, 0.3);
        ">
            ğŸ“„ {source["file"]} - s.{source["page"]}
        </span>
        '''
    
    html += '</div>'
    
    # Kaynak detaylarÄ±
    html += '<details style="margin-top: 8px;">'
    html += '<summary style="cursor: pointer; font-size: 13px; color: #6b7280; font-weight: 500;">ğŸ” DetaylarÄ± gÃ¶ster</summary>'
    html += '<div style="margin-top: 10px;">'
    
    for source in sources:
        html += f'''
        <div style="
            margin-top: 10px;
            padding: 12px;
            background: white;
            border-radius: 6px;
            border: 1px solid #e5e7eb;
        ">
            <div style="font-size: 12px; font-weight: 600; color: #667eea; margin-bottom: 6px;">
                #{source["index"]} - {source["file"]} (Sayfa {source["page"]})
            </div>
            <div style="font-size: 12px; color: #4b5563; line-height: 1.5;">
                {source["content"]}
            </div>
        </div>
        '''
    
    html += '</div></details></div>'
    return html


def chat_response(message, history):
    """Chat mesajÄ±nÄ± iÅŸle ve cevap dÃ¶ndÃ¼r"""
    if not message or not message.strip():
        return "âš ï¸ LÃ¼tfen bir soru yazÄ±n!"
    
    if rag_chain is None:
        return "âš ï¸ LÃ¼tfen Ã¶nce PDF dosyalarÄ± yÃ¼kleyin! 'Belge YÃ¶netimi' sekmesinden PDF ekleyebilirsiniz."
    
    try:
        # CevabÄ± al
        response = rag_chain.invoke(message.strip())
        
        # KaynaklarÄ± al ve formatla
        sources = get_sources(message.strip())
        sources_html = format_sources_html(sources)
        
        # Cevap + kaynaklarÄ± birleÅŸtir
        full_response = response + "\n\n" + sources_html
        
        return full_response
    except Exception as e:
        return f"âŒ Hata oluÅŸtu: {str(e)}"


def transcribe_audio(audio):
    """Ses kaydÄ±nÄ± metne Ã§evir"""
    if audio is None:
        return None
    
    try:
        # Ses dosyasÄ±nÄ± kaydet
        audio_path = os.path.join(audio_folder, "temp_recording.wav")
        
        # Gradio audio'dan gelen tuple: (sample_rate, audio_data)
        import soundfile as sf
        if isinstance(audio, tuple):
            sample_rate, audio_data = audio
            sf.write(audio_path, audio_data, sample_rate)
        else:
            audio_path = audio
        
        # Whisper ile transkripsiyonu al
        result = whisper_model.transcribe(audio_path, language="tr", fp16=False)
        question = result['text'].strip()
        
        return question
    
    except Exception as e:
        return f"âŒ Transkripsiyon hatasÄ±: {str(e)}"


def upload_pdf(files):
    """PDF dosyalarÄ±nÄ± yÃ¼kle ve veritabanÄ±nÄ± gÃ¼ncelle"""
    global vectorstore, rag_chain
    
    if not files:
        return "âš ï¸ LÃ¼tfen PDF dosyasÄ± seÃ§in!"
    
    try:
        uploaded_count = 0
        
        for file in files:
            # DosyayÄ± data klasÃ¶rÃ¼ne kopyala
            import shutil
            file_name = os.path.basename(file.name)
            dest_path = os.path.join(pdf_folder, file_name)
            shutil.copy(file.name, dest_path)
            uploaded_count += 1
        
        # VeritabanÄ±nÄ± yeniden oluÅŸtur
        vectorstore = initialize_vectorstore()
        rag_chain = create_rag_chain()
        
        return f"âœ… {uploaded_count} PDF dosyasÄ± baÅŸarÄ±yla yÃ¼klendi ve veritabanÄ± gÃ¼ncellendi!"
    
    except Exception as e:
        return f"âŒ Hata: {str(e)}"


def get_pdf_list():
    """YÃ¼klÃ¼ PDF dosyalarÄ±nÄ±n listesini al"""
    pdf_files = glob.glob(os.path.join(pdf_folder, "*.pdf"))
    if not pdf_files:
        return "ğŸ“š HenÃ¼z PDF yÃ¼klenmedi"
    
    file_list = "\n".join([f"â€¢ {os.path.basename(f)}" for f in pdf_files])
    return f"ğŸ“š YÃ¼klÃ¼ PDF DosyalarÄ± ({len(pdf_files)}):\n\n{file_list}"


# Gradio arayÃ¼zÃ¼
with gr.Blocks(
    title="ğŸ¦œ PapaÄŸan RAG",
    theme=gr.themes.Soft(
        primary_hue="blue",
        secondary_hue="indigo",
        font=gr.themes.GoogleFont("Inter"),
    ),
    css="""
        .gradio-container {
            max-width: 1200px !important;
        }
        /* Header stil */
        .app-header {
            text-align: center;
            padding: 30px 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 15px;
            margin-bottom: 20px;
            box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
        }
        .app-header h1 {
            font-size: 42px;
            margin: 0 0 8px 0;
            font-weight: 700;
        }
        .app-header p {
            font-size: 16px;
            margin: 0;
            opacity: 0.95;
        }
        /* Chat mesajlarÄ±nÄ± bÃ¼yÃ¼t */
        .message {
            font-size: 16px !important;
            line-height: 1.6 !important;
        }
        /* Input alanÄ±nÄ± bÃ¼yÃ¼t */
        .input-area textarea {
            font-size: 16px !important;
            min-height: 60px !important;
        }
        /* ButonlarÄ± bÃ¼yÃ¼t */
        button {
            font-size: 15px !important;
            font-weight: 500 !important;
        }
        /* Tab'larÄ± bÃ¼yÃ¼t */
        .tab-nav button {
            font-size: 16px !important;
            padding: 10px 16px !important;
        }
        /* Chatbot alanÄ±nÄ± geniÅŸlet */
        .chatbot {
            height: 600px !important;
        }
    """
) as app:
    
    # Header
    gr.HTML("""
        <div class="app-header">
            <h1>ğŸ¦œ PapaÄŸan RAG</h1>
            <p>Yapay Zeka Destekli Belge AsistanÄ± - ChatGPT TarzÄ± ArayÃ¼z</p>
        </div>
    """)
    
    with gr.Tabs():
        # Chat Sekmesi
        with gr.Tab("ğŸ’¬ Sohbet"):
            gr.Markdown("""
            ### ğŸ’¡ NasÄ±l KullanÄ±lÄ±r:
            - ğŸ’¬ KaysÄ±n bir chat gibi soru sorun, cevaplarÄ± message bubble'larda gÃ¶rÃ¼n
            - ğŸ¤ Ses kaydÄ± yapÄ±p metne Ã§evirebilirsiniz
            - ğŸ“š Her cevabÄ±n altÄ±nda hangi kaynaklardan bilgi alÄ±ndÄ±ÄŸÄ±nÄ± gÃ¶rebilirsiniz
            """)
            
            # Chat Interface
            chatbot = gr.Chatbot(
                label="Sohbet GeÃ§miÅŸi",
                height=600,
                show_copy_button=True
            )
            
            with gr.Row():
                with gr.Column(scale=4):
                    msg = gr.Textbox(
                        label="MesajÄ±nÄ±z",
                        placeholder="Sorunuzu buraya yazÄ±n... (Enter ile gÃ¶nder)",
                        lines=2,
                        max_lines=5,
                        show_label=False,
                        container=False
                    )
                with gr.Column(scale=1):
                    audio_record = gr.Audio(
                        label="ğŸ¤ Ses KaydÄ±",
                        type="numpy",
                        sources=["microphone"],
                        show_label=False
                    )
            
            with gr.Row():
                transcribe_btn = gr.Button("ğŸ™ï¸ Sesi Metne Ã‡evir", variant="secondary", size="sm")
                clear = gr.Button("ï¿½ï¸ Sohbeti Temizle", variant="stop", size="sm")
            
            # Chat fonksiyonlarÄ±
            def respond(message, chat_history):
                bot_message = chat_response(message, chat_history)
                chat_history.append((message, bot_message))
                return "", chat_history
            
            # Mesaj gÃ¶nderme
            msg.submit(respond, [msg, chatbot], [msg, chatbot])
            
            # Ses â†’ Metin
            transcribe_btn.click(
                fn=transcribe_audio,
                inputs=audio_record,
                outputs=msg
            )
            
            # Temizleme
            clear.click(lambda: None, None, chatbot, queue=False)
            
            gr.Markdown("""
            ---
            **ï¿½ Ä°puÃ§larÄ±:**
            - Uzun sohbetlerde "Sohbeti Temizle" ile yeni baÅŸlayabilirsiniz
            - Ses kaydÄ±ndan sonra metni dÃ¼zenleyebilirsiniz
            - Her cevabÄ±n altÄ±ndaki kaynaklara tÄ±klayarak detaylarÄ± gÃ¶rebilirsiniz
            """)
        
        # PDF YÃ¶netimi Sekmesi
        with gr.Tab("ğŸ“ Belge YÃ¶netimi"):
            gr.Markdown("## ğŸ“š PDF Belgelerini YÃ¶netin")
            
            with gr.Row():
                with gr.Column():
                    gr.Markdown("### ğŸ“¤ Yeni PDF YÃ¼kle")
                    pdf_upload = gr.File(
                        label="PDF DosyalarÄ±nÄ± SeÃ§in",
                        file_types=[".pdf"],
                        file_count="multiple",
                        height=150
                    )
                    upload_button = gr.Button(
                        "ğŸ“¤ YÃ¼kle ve Ä°ÅŸle",
                        variant="primary",
                        size="lg"
                    )
                    upload_status = gr.Textbox(
                        label="Durum",
                        lines=3,
                        interactive=False
                    )
                
                with gr.Column():
                    gr.Markdown("### ğŸ“‹ Sistemdeki PDF'ler")
                    pdf_list_button = gr.Button(
                        "ğŸ”„ Listeyi Yenile",
                        size="lg"
                    )
                    pdf_list = gr.Textbox(
                        label="YÃ¼klÃ¼ Dosyalar",
                        lines=12,
                        interactive=False,
                        value=get_pdf_list()
                    )
            
            upload_button.click(
                fn=upload_pdf,
                inputs=pdf_upload,
                outputs=upload_status
            ).then(
                fn=get_pdf_list,
                outputs=pdf_list
            )
            
            pdf_list_button.click(
                fn=get_pdf_list,
                outputs=pdf_list
            )
            
            gr.Markdown("""
            ---
            ### â„¹ï¸ Bilgilendirme:
            - ğŸ“š Birden fazla PDF dosyasÄ± yÃ¼kleyebilirsiniz
            - ğŸ”„ YÃ¼klenen dosyalar otomatik olarak vektÃ¶r veritabanÄ±na eklenir
            - âš¡ Maksimum 5 PDF dosyasÄ± iÅŸlenir (performans iÃ§in)
            - ğŸ’¾ Dosyalar `data` klasÃ¶rÃ¼ne kaydedilir
            - ğŸ—„ï¸ VektÃ¶r veritabanÄ± `chroma_db` klasÃ¶rÃ¼nde saklanÄ±r
            """)
        
        # Sistem Bilgisi Sekmesi
        with gr.Tab("â„¹ï¸ Bilgi"):
            gr.Markdown("""
            # ğŸ¦œ PapaÄŸan RAG HakkÄ±nda
            
            ## ğŸ”§ Sistem BileÅŸenleri
            
            ### ğŸ¤ Ses TanÄ±ma
            - **Model:** OpenAI Whisper (Medium)
            - **Dil:** TÃ¼rkÃ§e optimizasyonlu
            - **Cihaz:** """ + device + """
            
            ### ğŸ¤– Dil Modeli
            - **Model:** Llama 3 (8B parametreli)
            - **SÄ±caklÄ±k:** 0.1 (tutarlÄ± cevaplar iÃ§in)
            - **Ã‡alÄ±ÅŸtÄ±rma:** Ollama Ã¼zerinden
            
            ### ğŸ“Š Embedding ve Arama
            - **Embedding Modeli:** BAAI/bge-m3 (Ã‡ok dilli)
            - **VektÃ¶r VeritabanÄ±:** ChromaDB
            - **Chunk Boyutu:** 800 karakter
            - **Overlap:** 120 karakter
            - **Arama:** En benzer 6 dokÃ¼man
            
            ### ğŸ¨ ArayÃ¼z
            - **Framework:** Gradio
            - **Tema:** Soft (Blue/Indigo)
            - **Font:** Inter (Google Font)
            
            ## ï¿½ KullanÄ±m AkÄ±ÅŸÄ±
            
            1. **PDF YÃ¼kleme:** Belgelerinizi sisteme ekleyin
            2. **VektÃ¶rleÅŸtirme:** Belgeler otomatik olarak parÃ§alanÄ±r ve vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r
            3. **Soru Sorma:** Metin veya ses ile soru sorun
            4. **RAG SÃ¼reci:**
               - Sorunuz vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r
               - En ilgili belge parÃ§alarÄ± bulunur
               - Bu parÃ§alar LLM'e context olarak verilir
               - LLM sadece bu context'i kullanarak cevap Ã¼retir
            5. **Kaynak GÃ¶sterimi:** Hangi belgelerden bilgi alÄ±ndÄ±ÄŸÄ± gÃ¶sterilir
            
            ## âš¡ Ã–zellikler
            
            - âœ… ChatGPT tarzÄ± chat arayÃ¼zÃ¼
            - âœ… Sesli soru sorma
            - âœ… Ses â†’ metin dÃ¶nÃ¼ÅŸtÃ¼rme
            - âœ… Kaynak gÃ¶sterimi (citation chips)
            - âœ… Sohbet geÃ§miÅŸi
            - âœ… Ã‡oklu PDF desteÄŸi
            - âœ… TÃ¼rkÃ§e optimizasyon
            - âœ… ASCII-only output (uyumluluk iÃ§in)
            
            ## ğŸ¯ En Ä°yi SonuÃ§lar Ä°Ã§in
            
            - Spesifik ve net sorular sorun
            - PDF'lerinizin metin formatÄ±nda olmasÄ±na dikkat edin (taranmÄ±ÅŸ gÃ¶rÃ¼ntÃ¼ler deÄŸil)
            - Sistemde ilgili belgeler olduÄŸundan emin olun
            - Uzun sohbetlerde bazen temizleme yapmak performansÄ± artÄ±rÄ±r
            
            ---
            
            **GeliÅŸtirici Notu:** Bu sistem tamamen lokal Ã§alÄ±ÅŸÄ±r. Verileriniz dÄ±ÅŸarÄ± Ã§Ä±kmaz.
            """)
    
    # Footer
    gr.Markdown("""
    ---
    <div style="text-align: center; color: #6b7280; font-size: 14px;">
        <p>ğŸ¦œ PapaÄŸan RAG v1.0 | Powered by LangChain, Whisper & Llama 3</p>
    </div>
    """)


# UygulamayÄ± baÅŸlat
if __name__ == "__main__":
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )
